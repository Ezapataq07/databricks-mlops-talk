{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdc9f0a6-e455-4af3-9efe-f796335da683",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Model Training Notebook using Databricks Feature Store\n",
    "#\n",
    "# This notebook shows an example of a Model Training pipeline using Databricks Feature Store tables.\n",
    "# It is configured and can be executed as the \"Train\" task in the model_training_job workflow defined under\n",
    "# ``mlops_dbx/resources/model-workflow-resource.yml``\n",
    "#\n",
    "# Parameters:\n",
    "# * env (required):                 - Environment the notebook is run in (staging, or prod). Defaults to \"staging\".\n",
    "# * training_data_path (required)   - Path to the training data.\n",
    "# * experiment_name (required)      - MLflow experiment name for the training runs. Will be created if it doesn't exist.\n",
    "# * model_name (required)           - Three-level name (<catalog>.<schema>.<model_name>) to register the trained model in Unity Catalog. \n",
    "#  \n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a330ca66-d756-423d-a7f5-b30d16673630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65539550-ae66-48f5-8f61-f9b5921329aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c72a23-0e61-4157-bd60-e08ce5cd901c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Notebook arguments"
    }
   },
   "outputs": [],
   "source": [
    "# List of input args needed to run this notebook as a job.\n",
    "# Provide them via DB widgets or notebook arguments.\n",
    "\n",
    "# Notebook Environment\n",
    "dbutils.widgets.dropdown(\"env\", \"staging\", [\"dev\",\"staging\", \"prod\"], \"Environment Name\")\n",
    "env = dbutils.widgets.get(\"env\")\n",
    "\n",
    "# Path to the Hive-registered Delta table containing the training data.\n",
    "dbutils.widgets.text(\n",
    "    \"training_data_raw\",\n",
    "    \"mlops_dbx_talk_dev.churn.telco_churn_train_raw\",\n",
    "    label=\"Path to the training data\",\n",
    ")\n",
    "\n",
    "# MLflow experiment name.\n",
    "dbutils.widgets.text(\n",
    "    \"experiment_name\",\n",
    "    f\"/dev-mlops_dbx-experiment\",\n",
    "    label=\"MLflow experiment name\",\n",
    ")\n",
    "\n",
    "\n",
    "# Unity Catalog registered model name to use for the trained mode.\n",
    "dbutils.widgets.text(\n",
    "    \"model_name\", \"mlops_dbx_talk_dev.churn.telco_churn_model\", label=\"Full (Three-Level) Model Name\"\n",
    ")\n",
    "\n",
    "# Pickup features table name\n",
    "dbutils.widgets.text(\n",
    "    \"features_table\",\n",
    "    \"mlops_dbx_talk_dev.churn.telco_cust_features\",\n",
    "    label=\"Features Table\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40e367b7-c3d5-485c-82e1-48b0814337e6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define input and output variables"
    }
   },
   "outputs": [],
   "source": [
    "input_table_name = dbutils.widgets.get(\"training_data_raw\")\n",
    "experiment_name = dbutils.widgets.get(\"experiment_name\")\n",
    "model_name = dbutils.widgets.get(\"model_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18a774d4-292b-4b51-98d4-0a2b908eebc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "import mlflow\n",
    "from databricks.feature_engineering import FeatureLookup, FeatureEngineeringClient\n",
    "from mlflow.client import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32485b01-5d7f-42c9-aaeb-5b5c434d5a27",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Set experiment"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri('databricks-uc')\n",
    "\n",
    "if mlflow.get_experiment_by_name(experiment_name) is None:\n",
    "    mlflow.create_experiment(name=experiment_name)\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c42bffd7-065e-46a3-8f59-3868c5915704",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1768955618235}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": " Load raw data"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = spark.table(input_table_name).select(\n",
    "        f.col(\"customerID\").alias(\"customer_id\"),\n",
    "        f.when(f.col(\"Churn\") == \"Yes\", f.lit(1)).otherwise(f.lit(0)).cast(\"int\").alias(\"churn\")\n",
    "    )\n",
    "raw_data.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ba15c09-564a-4992-bde7-3a725417739b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Create FeatureLookups"
    }
   },
   "outputs": [],
   "source": [
    "features_table = dbutils.widgets.get(\"features_table\")\n",
    "\n",
    "feature_lookups = [\n",
    "    FeatureLookup(\n",
    "        table_name=features_table,\n",
    "        feature_names=None,\n",
    "        lookup_key=[\"customer_id\"],\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "434bd96c-5009-44ac-a874-e2ad726973ed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Create Training Dataset"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Since the rounded timestamp columns would likely cause the model to overfit the data\n",
    "# unless additional feature engineering was performed, exclude them to avoid training on them.\n",
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# Create the training set that includes the raw input data merged with corresponding features from both feature tables\n",
    "training_set = fe.create_training_set(\n",
    "    df=raw_data, # specify the df \n",
    "    feature_lookups=feature_lookups, \n",
    "    label=\"churn\",\n",
    ")\n",
    "\n",
    "\n",
    "# Load the TrainingSet into a dataframe which can be passed into sklearn for training a model\n",
    "training_df = training_set.load_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "054c697d-31b8-46d8-b485-5fa91f4c5493",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769469447695}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the training dataframe, and note that it contains both the raw input data and the features from the Feature Store\n",
    "training_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7b6e5ef-c796-4ece-b230-0d1450502dc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# End any existing runs (in the case this notebook is being run for a second time)\n",
    "mlflow.end_run()\n",
    "\n",
    "# Start an mlflow run, which is needed for the feature store to log the model\n",
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cad3e2b-2262-4d63-9078-23f1150b763c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numeric_features = [\"tenure_months\",\"tenure_years\",\"monthly_charges\",\"total_charges_filled\",\"avg_monthly_charge_lifetime\",\"abs_charges_gap\"]\n",
    "categorical_features = [\"gender\",\"internet_service\",\"contract_type\",\"payment_method\",\"tenure_bucket\",\"monthly_charge_bucket\"]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OrdinalEncoder(), categorical_features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest()),\n",
    "    ('classifier', LogisticRegression(random_state=29, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1081623b-087a-43c0-8441-ad478f6ddb67",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Train model"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "\t\t'classifier': [ LogisticRegression(random_state=29, n_jobs=-1)],\n",
    "\t\t'classifier__max_iter': [500, 750,1000],\n",
    "\t\t# 'classifier__max_depth': [5, 10, 20],\n",
    "        'feature_selection__k': [\"all\", 30, 15]\n",
    "\t}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "features_and_label = training_df.columns\n",
    "\n",
    "# Collect data into a Pandas array for training\n",
    "data = training_df.toPandas()[features_and_label]\n",
    "\n",
    "train, test = train_test_split(data, train_size=0.8,random_state=123)\n",
    "X_train = train.drop([\"customer_id\",\"churn\"], axis=1)\n",
    "X_test = test.drop([\"churn\"], axis=1)\n",
    "y_train = train.churn\n",
    "y_test = test.churn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mlflow.sklearn.autolog(log_input_examples=True, log_models=False, max_tuning_runs=30)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "y_pred_proba = grid_search.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c7ee674-de35-4423-b483-4f23465fbee0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Log model and return output."
    }
   },
   "outputs": [],
   "source": [
    "# Log the trained model with MLflow and package it with feature lookup information.\n",
    "signature = infer_signature(X_train, grid_search.predict(X_train))\n",
    "\n",
    "model_info = fe.log_model(\n",
    "    model=grid_search, #specify model\n",
    "    artifact_path=\"model_packaged\",\n",
    "    flavor=mlflow.sklearn,\n",
    "    training_set=training_set,\n",
    "    signature=signature,\n",
    "    registered_model_name=model_name,\n",
    ")\n",
    "\n",
    "eval_data = X_test\n",
    "eval_data[\"churn\"] = y_test\n",
    "eval_data[\"predicted_churn\"] = y_pred\n",
    "\n",
    "mlflow.evaluate(\n",
    "    # model_info.model_uri,\n",
    "    data=eval_data,\n",
    "    targets = \"churn\",\n",
    "    predictions=\"predicted_churn\",\n",
    "    model_type = \"classifier\"\n",
    ")\n",
    "\n",
    "mlflow.end_run()    \n",
    "\n",
    "# client = MlflowClient()\n",
    "# client.set_registered_model_alias(name=model_name, alias=\"staging\", version=model_info.version)\n",
    "\n",
    "# # The returned model URI is needed by the model deployment notebook.\n",
    "# model_version = get_latest_model_version(model_name)\n",
    "# model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "# dbutils.jobs.taskValues.set(\"model_uri\", model_uri)\n",
    "# dbutils.jobs.taskValues.set(\"model_name\", model_name)\n",
    "# dbutils.jobs.taskValues.set(\"model_version\", model_version)\n",
    "# dbutils.notebook.exit(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e10cbad-f258-4b4a-8ce5-2c9b75022cc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "run_id = model_info.run_id\n",
    "\n",
    "def find_version_by_run(model_name, run_id, max_wait_s=60):\n",
    "    for _ in range(max_wait_s):\n",
    "        for mv in client.search_model_versions(f\"name='{model_name}'\"):\n",
    "            if getattr(mv, \"run_id\", None) == run_id or str(mv.source).endswith('/model'):\n",
    "                return int(mv.version)\n",
    "        time.sleep(1)\n",
    "    return None\n",
    "\n",
    "version = getattr(model_info, \"registered_model_version\", None)\n",
    "if version is None:\n",
    "    version = find_version_by_run(model_name, run_id)\n",
    "    \n",
    "client.set_registered_model_alias(name=model_name, alias=\"staging\", version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b691aa3-1c6c-4a08-998a-007706646f5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(train).write.mode(\"overwrite\").saveAsTable(\"mlops_dbx_talk_dev.churn.telco_churn_train\")\n",
    "spark.createDataFrame(test).write.mode(\"overwrite\").saveAsTable(\"mlops_dbx_talk_dev.churn.telco_churn_validation\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "databricks-feature-engineering"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": {
    "autoRunOnWidgetChange": "auto-run-selected-command"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4,
    "widgetLayout": []
   },
   "notebookName": "TrainWithFeatureStore",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "2b81ebd5-a5cf-4926-9754-97cd2b8606e9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "staging",
      "label": "Environment Name",
      "name": "env",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "dev",
        "staging",
        "prod"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "staging",
      "label": "Environment Name",
      "name": "env",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "dev",
        "staging",
        "prod"
       ]
      }
     }
    },
    "experiment_name": {
     "currentValue": "/Workspace/Shared/mlops_talk/telco_churn_model",
     "nuid": "66fa1fa6-1b82-44f1-8593-336431dbe5f4",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/dev-mlops_dbx-experiment",
      "label": "MLflow experiment name",
      "name": "experiment_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/dev-mlops_dbx-experiment",
      "label": "MLflow experiment name",
      "name": "experiment_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "features_table": {
     "currentValue": "mlops_dbx_talk_dev.churn.telco_cust_features",
     "nuid": "2b2b158c-7c41-4d3b-8b80-bf46dbc4a7ed",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "mlops_dbx_talk_dev.churn.telco_cust_features",
      "label": "Features Table",
      "name": "features_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "mlops_dbx_talk_dev.churn.telco_cust_features",
      "label": "Features Table",
      "name": "features_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model_name": {
     "currentValue": "mlops_dbx_talk_dev.churn.telco_churn_model",
     "nuid": "31358549-d035-4f8b-80a3-e804b7c8cff0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "mlops_dbx_talk_dev.churn.telco_churn_model",
      "label": "Full (Three-Level) Model Name",
      "name": "model_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "mlops_dbx_talk_dev.churn.telco_churn_model",
      "label": "Full (Three-Level) Model Name",
      "name": "model_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "training_data_raw": {
     "currentValue": "mlops_dbx_talk_dev.churn.telco_churn_train_raw",
     "nuid": "5f7c4dbb-e59f-49a7-aa81-494d1bff72d5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "mlops_dbx_talk_dev.churn.telco_churn_train_raw",
      "label": "Path to the training data",
      "name": "training_data_raw",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "mlops_dbx_talk_dev.churn.telco_churn_train_raw",
      "label": "Path to the training data",
      "name": "training_data_raw",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
