{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2afb846-abd3-469a-bd3f-88d23c96f051",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Batch Inference Notebook\n",
    "#\n",
    "# This notebook is an example of applying a model for batch inference against an input delta table,\n",
    "# It is configured and can be executed as the batch_inference_job in the batch_inference_job workflow defined under\n",
    "# ``mlops_dbx/resources/batch-inference-workflow-resource.yml``\n",
    "#\n",
    "# Parameters:\n",
    "#\n",
    "#  * env (optional)  - String name of the current environment (dev, staging, or prod). Defaults to \"dev\"\n",
    "#  * input_table_name (required)  - Delta table name containing your input data.\n",
    "#  * output_table_name (required) - Delta table name where the predictions will be written to.\n",
    "#                                   Note that this will create a new version of the Delta table if\n",
    "#                                   the table already exists\n",
    "#  * model_name (required) - The name of the model to be used in batch inference.\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "# List of input args needed to run the notebook as a job.\n",
    "# Provide them via DB widgets or notebook arguments.\n",
    "#\n",
    "# Name of the current environment\n",
    "dbutils.widgets.dropdown(\"env\", \"dev\", [\"dev\", \"staging\", \"prod\"], \"Environment Name\")\n",
    "# A Hive-registered Delta table containing the input features.\n",
    "dbutils.widgets.text(\"input_table_name\", \"\", label=\"Input Table Name\")\n",
    "# Delta table to store the output predictions.\n",
    "dbutils.widgets.text(\"output_table_name\", \"\", label=\"Output Table Name\")\n",
    "dbutils.widgets.text(\"label_table_name\", \"\", label=\"Label Table Name\")\n",
    "dbutils.widgets.text(\"inference_table_name\", \"\", label=\"Inference Table Name\")\n",
    "# Unity Catalog registered model name to use for the trained mode.\n",
    "dbutils.widgets.text(\n",
    "    \"model_name\", \"dev.mlops_dbx.mlops_dbx-model\", label=\"Full (Three-Level) Model Name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00523a03-e4c9-4ef5-aef8-7349f5af8cf8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define input and output variables"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "env = dbutils.widgets.get(\"env\")\n",
    "input_table_name = dbutils.widgets.get(\"input_table_name\")\n",
    "output_table_name = dbutils.widgets.get(\"output_table_name\")\n",
    "label_table_name = dbutils.widgets.get(\"label_table_name\")\n",
    "inference_table_name = dbutils.widgets.get(\"inference_table_name\")\n",
    "model_name = dbutils.widgets.get(\"model_name\")\n",
    "assert input_table_name != \"\", \"input_table_name notebook parameter must be specified\"\n",
    "assert output_table_name != \"\", \"output_table_name notebook parameter must be specified\"\n",
    "assert model_name != \"\", \"model_name notebook parameter must be specified\"\n",
    "alias = \"champion\"\n",
    "model_uri = f\"models:/{model_name}@{alias}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baa51576-ee2b-4081-aaef-53f97a7dbb63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "# Get model version from alias\n",
    "client = MlflowClient(registry_uri=\"databricks-uc\")\n",
    "model_version = client.get_model_version_by_alias(model_name, alias).version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c44592de-0dfd-4d93-a8f4-12993512281a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get datetime\n",
    "from datetime import datetime\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "405a4525-8e6a-4dfa-9054-db2b7ca3f916",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load model and run inference"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from batch_inference.predict import predict_batch\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "input_table = spark.table(input_table_name).select(\n",
    "                f.col(\"customerID\").alias(\"customer_id\"))\n",
    "\n",
    "predict_batch(model_uri, input_table, output_table_name, model_version, ts)\n",
    "\n",
    "df_curr_preds = spark.table(output_table_name).join(spark.table(label_table_name), on='customer_id', how='inner').select('customer_id','model_id',f.col('prediction').cast('integer'),'churn','timestamp')\n",
    "\n",
    "df_curr_preds.write.mode(\"append\").saveAsTable(inference_table_name)\n",
    "\n",
    "spark.sql(f\"ALTER TABLE {inference_table_name}\n",
    "  SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
    "\n",
    "dbutils.notebook.exit(output_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91b55706-92d1-4466-8715-ea9f3b51af73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "databricks-feature-engineering"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BatchInference",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "89528b8e-1938-4ef4-83c1-bdff635476a2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev",
      "label": "Environment Name",
      "name": "env",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "dev",
        "staging",
        "prod"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "dev",
      "label": "Environment Name",
      "name": "env",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "dev",
        "staging",
        "prod"
       ]
      }
     }
    },
    "inference_table_name": {
     "currentValue": "mlops_dbx_talk_dev.churn.telco_churn_inference_table",
     "nuid": "894ffd23-41dc-4787-b575-4965ede27502",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Inference Table Name",
      "name": "inference_table_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Inference Table Name",
      "name": "inference_table_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "input_table_name": {
     "currentValue": "mlops_dbx_talk_dev.churn.telco_churn_inference_raw",
     "nuid": "f04571ea-60b7-4e39-982e-e1c69b0e573c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Input Table Name",
      "name": "input_table_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Input Table Name",
      "name": "input_table_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "label_table_name": {
     "currentValue": "mlops_dbx_talk_dev.churn.telco_cust_labels",
     "nuid": "702f40c1-5649-4757-ba54-126dd01edd21",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Label Table Name",
      "name": "label_table_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Label Table Name",
      "name": "label_table_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model_name": {
     "currentValue": "mlops_dbx_talk_dev.churn.telco_churn_model",
     "nuid": "55c13dc1-f21d-4270-b8b0-2a4122653879",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev.mlops_dbx.mlops_dbx-model",
      "label": "Full (Three-Level) Model Name",
      "name": "model_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev.mlops_dbx.mlops_dbx-model",
      "label": "Full (Three-Level) Model Name",
      "name": "model_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "output_table_name": {
     "currentValue": "mlops_dbx_talk_dev.churn.telco_churn_scores",
     "nuid": "07968c21-72a8-4c43-997c-1030b64cd6f9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Output Table Name",
      "name": "output_table_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Output Table Name",
      "name": "output_table_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
